---
title: "[AutoML] PyCaret í˜„ ì‹œì  ê°€ì¥ ì™„ë²½í•œ AutoML ë¼ì´ë¸ŒëŸ¬ë¦¬"
date: 2020-10-26
permalink: /dev/post15
tags : AutoML
categories: machine-learning
---


### ì˜¤í”ˆì†ŒìŠ¤ Low-Code íŒŒì´ì¬ ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬

<p align="center">
  <img src="https://avatars1.githubusercontent.com/u/58118658?s=460&u=93d2659aa7c1a6b8fecc15b87a2bad4d8b0022fb&v=4" width="250" />
</p>

PyCaretì€ scikit-learn , XGBoost , Microsoft LightGBM , spaCy ë“±ê³¼ ê°™ì€ ì—¬ëŸ¬ ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í”„ë ˆì„ì›Œí¬ë¥¼ í¬í•¨í•œ Python wrapper ì´ë‹¤. í˜„ì¬ ìµœì‹ ë²„ì „ì€ 2.1ì´ê³ , [ê³µì‹ ê¹ƒí—™](https://github.com/pycaret/pycaret)ì—ì„œ Stars ê°œìˆ˜ê°€ 2.4kë¥¼ ê¸°ë¡í•˜ê³  ìˆë‹¤. ì½”ë“œëŠ” 2019ë…„ì— 2.0 ë²„ì „ë¶€í„° ì˜¤í”ˆí•œ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤. ê°œë°œ ë””íœë˜ì‹œë¥¼ ë³´ë©´ ì™ ë§Œí•œ íŒŒì´ì¬ ê¸°ë°˜ ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë‹¤ ê±´ë“œë¦¬ê³  ìˆë‹¤. í˜„ ì‹œì ì—ì„œ ê°€ì¥ AutoMLì„ ì˜ êµ¬í˜„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì¸ ë“¯ í•˜ë‹¤. ì‹¬ì§€ì–´ Tensorflowê¹Œì§€ í¬í•¨ì‹œí‚¤ë ¤ê³  ì¤€ë¹„ì¤‘ì¸ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤. ì–´ë–»ê²Œ ë”¥ëŸ¬ë‹ ì›Œí¬í”Œë¡œìš°ë¥¼ í†µí•©í• ì§€ ê¸°ëŒ€ëœë‹¤.

[ê³µì‹ í™ˆí˜ì´ì§€ íŠœí† ë¦¬ì–¼](https://pycaret.org/tutorial/)ë„ ì´ˆë³´ì/ì¤‘ê¸‰ìë³„, ëª¨ë¸ë³„ë¡œ ì˜ ë§Œë“¤ì–´ì ¸ ìˆì–´ì„œ ì‚¬ìš©ìê°€ ì‰½ê²Œ ë¨¸ì‹ ëŸ¬ë‹ì— ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í–ˆë‹¤. êµ‰ì¥íˆ ì§ê´€ì ì¸ í•¨ìˆ˜ ì´ë¦„ìœ¼ë¡œ ëª¨ë¸ ìƒì„±ì´ ê°€ëŠ¥í•˜ë‹¤. ì˜ˆë¥¼ ë“¤ë©´ create_model()ë¡œ ëª¨ë¸ ê°ì²´ë¥¼ ìƒì„±í•˜ê³ , compare_models()ë¡œ ì—¬ëŸ¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•œë‹¤. tune_model(), ensemble_model(), plot_model() í•¨ìˆ˜ë¡œ íŒŒë¼ë¯¸í„° íŠœë‹ê³¼ ì‹œê°í™”ë¥¼ í•  ìˆ˜ ìˆë‹¤. SHAP ê¸°ë°˜ì˜ ëª¨ë¸ í•´ì„ ê¸°ëŠ¥ì¸ interpret_model()ë„ ì œê³µí•œë‹¤. (ì´ì¯¤ë˜ë©´ ê·¸ëƒ¥ ì•ˆë˜ëŠ”ê²Œ ì—†ë‹¤ê³  ë³´ë©´ ë ë“¯..) ê·¸ë¦¬ê³  ì´ë ‡ê²Œë§Œ ë†“ê³  ë´ë„ **ì´ê²ƒì´ ë°”ë¡œ AutoML ì´ë‹¤**ì¸ë°, automl()ì´ë¼ëŠ” í•¨ìˆ˜ë„ ë˜ ìˆë‹¤. ë˜(!) MLOpsë¡œ ìœ ëª…í•œ MLFlowë„ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤ğŸ˜²

PyCaretì€ ë¨¸ì‹ ëŸ¬ë‹ ì „ë¬¸ê°€ì™€ ë¹„ì „ë¬¸ê°€ ëª¨ë‘ì—ê²Œ ìœ ìš©í•˜ë‹¤. PyCaretê³¼ ìœ ì‚¬í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ìˆì–´ë„, PyCaretë¥¼ ëŒ€ì²´í•  ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë‚˜ì˜¤ì§€ ì•Šì„ ê²ƒ ê°™ë‹¤. (ê¸°ì¡´ì˜ AutoML ë¼ì´ë¸ŒëŸ¬ë¦¬ë¼ê³  í•´ì„œ ì‚¬ìš©ë˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì€ ì‚¬ì‹¤ ì „ì²´ ML í”„ë¡œì„¸ìŠ¤ì˜ í•œ ë¶€ë¶„ì„ ë‹´ë‹¹í•˜ê³  ìˆì„ ë¿ì´ì—ˆë‹¤.) PyCaretì´ ë²„ì „ì„ ì˜¬ë¦¬ë©´ì„œ ì ì  ê¸°ì¡´ì˜ ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í¬í•¨ì‹œì¼œì¤€ë‹¤ë©´ ì§€ê¸ˆë³´ë‹¤ ë” ìœ ëª…í•´ì§€ê³  ë§ˆì¹˜ scikit-learnì´ ê·¸ë¬ë˜ ê²ƒê³¼ ê°™ì´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©ë  í™•ë¥ ì´ ë†’ë‹¤. (ì´ë¯¸ PyCaretì´ scikit-learn ê¸°ëŠ¥ì„ í¬í•¨í•˜ê³  ìˆê³ , scikit-learnì˜ ì‚¬ìš©ì„±ì„ ë†’ì˜€ê¸° ë•Œë¬¸ì— ë‹¹ì—°íˆ ê·¸ëŸ´ ê²ƒì´ë‹¤.)

ì•„ë˜ëŠ” [ì—¬ê¸°](https://github.com/pycaret/pycaret)ì—ì„œ ê¸°ë³¸ì ì¸ ì§€ë„í•™ìŠµ íŠœí† ë¦¬ì–¼ì„ ì˜®ê²¨ì˜¨ ê²ƒì´ë‹¤.

### 0. ì„¤ì¹˜

```cmd
pip install pycaret
```

<br>

ğŸŠ Step-by-Step Tutorial **[ì˜¤ë¦¬ì§€ë„ í¬ìŠ¤íŒ… ì£¼ì†Œ](https://towardsdatascience.com/announcing-pycaret-an-open-source-low-code-machine-learning-library-in-python-4a1f1aad8d46)**

### **1. Getting Data**

In this step-by-step tutorial, we will use â€˜diabetesâ€™ dataset and the goal is to predict patient outcome (binary 1 or 0) based on several factors such as Blood Pressure, Insulin Level, Age etc. The dataset is available on PyCaretâ€™s github repository. Easiest way to import dataset directly from repository is by using **get_data** function from **pycaret.datasets** modules.

```python
from pycaret.datasets import get_data
diabetes = get_data('diabetes')
```

### **2. Setting up Environment**

The first step of any machine learning experiment in PyCaret is setting up the environment by importing the required module and initializing **setup( )**. The module used in this example is pycaret.classification.

Once the module is imported, **setup()** is initialized by defining the dataframe (â€˜diabetesâ€™) and the target variable (â€˜Class variableâ€™).

```python
from pycaret.classification import *
exp1 = setup(diabetes, target = 'Class variable')
```

All the preprocessing steps are applied within **setup()**. With over 20 features to prepare data for machine learning, PyCaret creates a transformation pipeline based on the parameters defined in setup function. It automatically orchestrates all dependencies in a **pipeline** so that you donâ€™t have to manually manage the sequential execution of transformations on test or unseen dataset. PyCaretâ€™s pipeline can easily be transferred across environments to run at scale or be deployed in production with ease. Below are preprocessing features available in PyCaret as of its first release.

![ì´ë¯¸ì§€](https://miro.medium.com/max/1400/1*jo9vPsQhQZmyXUhnrt9akQ.png)
Preprocessing capabilities of PyCaret

ğŸ’¡ Data Preprocessing steps that are compulsory(í•„ìˆ˜ì ì¸) for machine learning such as missing values imputation, categorical variable encoding, label encoding (converting yes or no into 1 or 0), and train-test-split are automatically performed when setup() is initialized. [Click here](https://pycaret.org/preprocessing/) to learn more about PyCaretâ€™s preprocessing abilities.

### **3. Compare Models**

This is the first step recommended in **supervised machine learning** experiments (classification or regression). This function trains all the models in the model library and compares the common evaluation metrics using k-fold cross validation (by default 10 folds). The evaluation metrics used are:

- For Classification: Accuracy, AUC, Recall, Precision, F1, Kappa
- For Regression: MAE, MSE, RMSE, R2, RMSLE, MAPE

```python
compare_models()
```

![ì´ë¯¸ì§€](https://miro.medium.com/max/1400/1*WaaSiqUkIFMiKbYofBRo7Q.png)
Output from compare_models( ) function

ğŸ’¡ Metrics are evaluated using 10-fold cross validation by default. It can be changed by changing the value of fold parameter.

ğŸ’¡ Table is sorted by â€˜Accuracyâ€™ (Highest to Lowest) value by default. It can be changed by changing the value of sort parameter.

### **4. Create Model**

Creating a model in any module of PyCaret is as simple as writing **create_model**. It takes only one parameter i.e. the model name passed as string input. This function returns a table with k-fold cross validated scores and a trained model object.

```python
adaboost = create_model('ada')
```

Variable â€˜adaboostâ€™ stores a trained model object returned by **create_model** function is a scikit-learn estimator. Original attributes of a trained object can be accessed by using period ( . ) after variable. See example below.

```python
adaboost.base_estimator_
adaboost.feature_importances_
```

ğŸ’¡ PyCaret has over 60 open source ready-to-use algorithms. [Click here](https://pycaret.org/create-model/) to see a complete list of estimators / models available in PyCaret.

### **5. Tune Model**

The **tune_model** function is used for automatically tuning hyperparameters of a machine learning model. PyCaret uses **random grid search** over a predefined search space. This function returns a table with k-fold cross validated scores and a trained model object.

```python
tuned_adaboost = tune_model('ada')
```

![ì´ë¯¸ì§€](https://miro.medium.com/max/1400/1*pqsFYecRxZ_ruvwBXZWlQA.png)

ğŸ’¡ The **tune_model** function in unsupervised modules such as pycaret.nlp, pycaret.clustering and pycaret.anomaly can be used in conjunction with supervised modules. For example, PyCaretâ€™s NLP module can be used to tune number of topics parameter by evaluating an objective / cost function from a supervised ML model such as â€˜Accuracyâ€™ or â€˜R2â€™.

### **6. Ensemble Model**

The **ensemble_model** function is used for ensembling trained models. It takes only one parameter i.e. a trained model object. This functions returns a table with k-fold cross validated scores and a trained model object.

```python
# creating a decision tree model
dt = create_model('dt')
# ensembling a trained dt model
dt_bagged = ensemble_model(dt)
```

![ì´ë¯¸ì§€](https://miro.medium.com/max/1400/1*uw2WmHc1oFeUfnnz-jYfhA.png)

ğŸ’¡ â€˜Baggingâ€™ method is used for ensembling by default which can be changed to â€˜Boostingâ€™ by using the **method** parameter within the ensemble_model function.

ğŸ’¡ PyCaret also provide <U>blend_models</U> and <U>stack_models</U> functionality to ensemble multiple trained models.

### **7. Plot Model**

Performance evaluation and diagnostics of a trained machine learning model can be done using the **plot_model** function. It takes a trained model object and the type of plot as a string input within the **plot_model** function.

```python
# create a model
adaboost = create_model('ada')
# AUC plot
plot_model(adaboost, plot = 'auc')
# Decision Boundary
plot_model(adaboost, plot = 'boundary')
# Precision Recall Curve
plot_model(adaboost, plot = 'pr')
# Validation Curve
plot_model(adaboost, plot = 'vc')
```

![ì´ë¯¸ì§€](https://miro.medium.com/max/1400/1*JnfDw9wwuGxTDS676_hBXg.png)

[Click here](https://pycaret.org/plot-model/) to learn more about different visualization in PyCaret.

Alternatively, you can use **evaluate_model** function to see plots via user interface within notebook.

```python
evaluate_model(adaboost)
```

![ì´ë¯¸ì§€](https://miro.medium.com/max/1400/1*TMuREzi-o7_edYCj4yIZfA.gif)

ğŸ’¡ **plot_model** function in **pycaret.nlp** module can be used to visualize _text corpus_ and _semantic topic models_. [Click here](https://pycaret.org/plot-model/#nlp) to learn more about it.

### **8. Interpret Model**

When the relationship in data is non-linear which is often the case in real life we invariably see tree-based models doing much better than simple gaussian models. However, this comes at the cost of losing interpretability as tree-based models do not provide simple coefficients like linear models. PyCaret implements <U>SHAP (SHapley Additive exPlanations)</U> using **interpret_model** function.

```python
# create a model
xgboost = create_model('xgboost')
# summary plot
interpret_model(xgboost)
# correlation plot
interpret_model(xgboost, plot = 'correlation')
```

![ì´ë¯¸ì§€](https://miro.medium.com/max/1400/1*ct0UFJA2sxTpSTwSwO1-fQ.png)

Interpretation of a <U>particular datapoint</U> (also known as reason argument) in the test dataset can be evaluated using â€˜reasonâ€™ plot. In the below example we are checking the first instance in our test dataset.

```python
interpret_model(xgboost, plot = 'reason', observation = 0)
```

![ì´ë¯¸ì§€](https://miro.medium.com/max/1400/1*hsM128hQ2sDk9TnTHBH9Bw.png)

### **9. Predict Model**

So far the results we have seen are based on k-fold cross validation on training dataset only (70% by default). In order to see the predictions and performance of the model on the test / hold-out dataset, the **predict_model** function is used.

```python
# create a model
rf = create_model('rf')
# predict test / hold-out dataset
rf_holdout_pred = predict_model(rf)
```

![ì´ë¯¸ì§€](https://miro.medium.com/max/1400/1*e05Sd2KFexSjxORcaxAeFw.png)

**predict_model** function is also used to predict unseen dataset. For now, we will use the same dataset we have used for training as a _proxy_ for new unseen dataset. In practice, **predict_model** function would be used iteratively, every time with a new unseen dataset.

```python
predictions = predict_model(rf, data = diabetes)
```

![ì´ë¯¸ì§€](https://miro.medium.com/max/1400/1*TZwr8fI9cNqluSwnDa4IfA.png)

ğŸ’¡ predict_model function can also predict a sequential chain of models which are created using <U>stack_models</U> and <U>create_stacknet</U> function.

ğŸ’¡ predict_model function can also predict directly from the model hosted on AWS S3 using <U>deploy_model</U> function.

### **10. Deploy Model**

One way to utilize the trained models to generate predictions on an unseen dataset is by using the predict_model function in the same notebooks / IDE in which model was trained. However, making the prediction on an unseen dataset is an iterative process; depending on the use-case, the frequency of making predictions could be from real time predictions to batch predictions. PyCaretâ€™s **deploy_model** function allows deploying the entire pipeline including trained model on cloud from notebook environment.

```python
deploy_model(model = rf,
            model_name = 'rf_aws',
            platform = 'aws',
            authentication =  {'bucket':'pycaret-test'})
```

### **11. Save Model / Save Experiment**

Once training is completed the entire pipeline containing all preprocessing transformations and trained model object can be saved as a binary pickle file.

```python
# creating model
adaboost = create_model('ada')
# saving model
save_model(adaboost, model_name = 'ada_for_deployment')
```

You can also save the entire experiment consisting of all intermediary outputs as one binary file.

```python
save_experiment(experiment_name = 'my_first_experiment')
```

ğŸ’¡ You can load saved model and saved experiment using **load_model** and **load_experiment** function available in all modules of PyCaret



